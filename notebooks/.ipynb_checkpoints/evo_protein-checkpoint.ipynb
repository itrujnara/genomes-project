{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9789e023-e22c-4c4a-90fd-567296eb2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from functools import cache\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from evo import Evo\n",
    "from evo.generation import Generator\n",
    "\n",
    "from Bio import Seq, SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c3db16-b878-4d26-8365-5395c45cfd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run models on GPU if GPU node is used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f08ed86-ed8b-4151-b1ea-e46f30bf6dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b55bdf13d3243d7b707e64ca3334a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the model\n",
    "evo_model = Evo(\"evo-1.5-8k-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e2e920-968a-4bfb-8c46-648804135e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract torch modules\n",
    "tokenizer = evo_model.tokenizer\n",
    "model = evo_model.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7669a5ea-745a-48da-8fc2-4cce5c514c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a generator object\n",
    "generator = Generator(model, tokenizer, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470a78d-b19d-453f-aee4-5228ea840409",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SeqStats:\n",
    "    \"\"\"Dataclass for storing generation parameters and metrics.\"\"\"\n",
    "    biotype: str\n",
    "    index: int\n",
    "    mock: bool\n",
    "    k_fit: int\n",
    "    k_test: int\n",
    "    correctness: float\n",
    "    auroc: float\n",
    "    auprc: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c996b1c-6939-47fc-9109-c846def61812",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_forward_stats(seq_fit, seq_test, generator, *, biotype=\"unknown\", index=0, mock=False, seed=None) -> SeqStats:\n",
    "    \"\"\"Generate a sequence and calculate metrics.\"\"\"\n",
    "    k_fit = len(seq_fit)\n",
    "    k_test = len(seq_test)\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    test_tokens = torch.tensor(tokenizer.tokenize(seq_test))\n",
    "    gen_tokens, scores, _ = generator.generate(\"cuda\", input_string=seq_fit, num_tokens=k_test,\n",
    "                                               cached_generation=True)\n",
    "\n",
    "    test_seq = Seq.Seq(seq_test)\n",
    "    test_aa = test_seq.translate()\n",
    "    gen_seq = Seq.Seq(tokenizer.detokenize(gen_tokens))\n",
    "    gen_aa = gen_seq.translate()\n",
    "    correct = [a == b for a,b in zip(list(test_aa.seq), list(gen_aa.seq))]\n",
    "    correctness = correct.to(torch.float).mean().item()\n",
    "\n",
    "    test_probs = F.one_hot(test_tokens.to(torch.int64))[:,(65,67,71,84)]\n",
    "    gen_acgt_logits = scores[0,:,(65,67,71,84)]\n",
    "    gen_acgt_probs = torch.softmax(gen_acgt_logits, dim=-1).to(\"cpu\")\n",
    "    auroc = roc_auc_score(test_probs, gen_acgt_probs, average=\"weighted\")\n",
    "\n",
    "    auprc = average_precision_score(test_probs, gen_acgt_probs, average=\"weighted\")\n",
    "\n",
    "    return SeqStats(biotype=biotype,\n",
    "                    index=index,\n",
    "                    mock=mock,\n",
    "                    k_fit=k_fit,\n",
    "                    k_test=k_test,\n",
    "                    correctness=correctness,\n",
    "                    auroc=auroc,\n",
    "                    auprc=auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b641de07-91a1-47c9-b953-e59135e1194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"seqs/cds_1.fa\") as f:\n",
    "    seqs = SeqIO.parse(f, \"fasta\")\n",
    "    seq = next(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b4e8b6-6401-43f0-a8d8-6225ebb90f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('MSAPSEEEEYARLVMEAQPEWLRAEVKRLSHELAETTREKIQAAEYGLAVLEEK...ALV')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_nuc = seq.seq[:900]\n",
    "fit_aa = Seq.Seq(fit_nuc).translate()\n",
    "fit_aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
